{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adadelta\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "ada = Adadelta(lr=1.0)\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer=ada, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train[0:5000].astype('float32') / 255.\n",
    "x_test = x_test[0:1000].astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "5000/5000 [==============================] - 10s - loss: 0.2102 - val_loss: 0.1183\n",
      "Epoch 2/5\n",
      "5000/5000 [==============================] - 9s - loss: 0.1161 - val_loss: 0.1053\n",
      "Epoch 3/5\n",
      "5000/5000 [==============================] - 9s - loss: 0.1122 - val_loss: 0.1044\n",
      "Epoch 4/5\n",
      "5000/5000 [==============================] - 9s - loss: 0.1118 - val_loss: 0.1042\n",
      "Epoch 5/5\n",
      "5000/5000 [==============================] - 9s - loss: 0.1117 - val_loss: 0.1041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b7f0557d5f8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=5,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAADqCAYAAAAlBtnSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAA88P9lduuTJXJT5gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b7f0559a240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i+1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n + 1)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/willj/anaconda3/envs/GTEx/lib/python3.5/site-packages/keras/engine/topology.py:1500: UserWarning: Model inputs must come from a Keras Input layer, they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"model_7\" was not an Input tensor, it was generated by layer custom_variational_layer_7.\n",
      "Note that input tensors are instantiated via `tensor = Input(shape)`.\n",
      "The tensor that caused the issue was: input_7:0\n",
      "  str(x.name))\n",
      "/homes/willj/anaconda3/envs/GTEx/lib/python3.5/site-packages/keras/engine/training.py:729: UserWarning: Output \"custom_variational_layer_7\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"custom_variational_layer_7\" during training.\n",
      "  '\" during training.')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda, Layer\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.datasets import mnist\n",
    "\n",
    "batch_size = 100\n",
    "original_dim = 784\n",
    "latent_dim = 2\n",
    "intermediate_dim = 256\n",
    "epochs = 50\n",
    "epsilon_std = 1.0\n",
    "\n",
    "\n",
    "x = Input(batch_shape=(batch_size, original_dim))\n",
    "h = Dense(intermediate_dim, activation='relu')(x)\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_var = Dense(latent_dim)(h)\n",
    "\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0.,\n",
    "                              stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "# we instantiate these layers separately so as to reuse them later\n",
    "decoder_h = Dense(intermediate_dim, activation='relu')\n",
    "decoder_mean = Dense(original_dim, activation='sigmoid')\n",
    "h_decoded = decoder_h(z)\n",
    "x_decoded_mean = decoder_mean(h_decoded)\n",
    "\n",
    "\n",
    "# Custom loss layer\n",
    "class CustomVariationalLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.is_placeholder = True\n",
    "        super(CustomVariationalLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def vae_loss(self, x, x_decoded_mean):\n",
    "        xent_loss = original_dim * metrics.binary_crossentropy(x, x_decoded_mean)\n",
    "        kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "        return K.mean(xent_loss + kl_loss)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs[0]\n",
    "        x_decoded_mean = inputs[1]\n",
    "        loss = self.vae_loss(x, x_decoded_mean)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        # We won't actually use the output.\n",
    "        return x\n",
    "\n",
    "y = CustomVariationalLayer()([x, x_decoded_mean])\n",
    "vae = Model(x, y)\n",
    "vae.compile(optimizer='rmsprop', loss=None)\n",
    "\n",
    "\n",
    "# train the VAE on MNIST digits\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def info(type, value, tb):\n",
    "    if hasattr(sys, 'ps1') or not sys.stderr.isatty():\n",
    "    # we are in interactive mode or we don't have a tty-like\n",
    "    # device, so we call the default hook\n",
    "        sys.__excepthook__(type, value, tb)\n",
    "    else:\n",
    "        import traceback, pdb\n",
    "        # we are NOT in interactive mode, print the exception...\n",
    "        traceback.print_exception(type, value, tb)\n",
    "        print\n",
    "        # ...then start the debugger in post-mortem mode.\n",
    "        # pdb.pm() # deprecated\n",
    "        pdb.post_mortem(tb) # more \"modern\"\n",
    "\n",
    "sys.excepthook = info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-a26d19846770>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         validation_data=None)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/homes/willj/anaconda3/envs/GTEx/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1483\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/homes/willj/anaconda3/envs/GTEx/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1138\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/homes/willj/anaconda3/envs/GTEx/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2070\u001b[0m                                           np.expand_dims(sparse_coo.col, 1)), 1)\n\u001b[1;32m   2071\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_coo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_coo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "\n",
    "vae.fit(x_train,\n",
    "        shuffle=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_3 (InputLayer)             (100, 784)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_11 (Dense)                 (100, 256)            200960                                       \n",
      "____________________________________________________________________________________________________\n",
      "dense_12 (Dense)                 (100, 2)              514                                          \n",
      "____________________________________________________________________________________________________\n",
      "dense_13 (Dense)                 (100, 2)              514                                          \n",
      "____________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)                (100, 2)              0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_14 (Dense)                 (100, 256)            768                                          \n",
      "____________________________________________________________________________________________________\n",
      "dense_15 (Dense)                 (100, 784)            201488                                       \n",
      "____________________________________________________________________________________________________\n",
      "custom_variational_layer_3 (Cust [(100, 784), (100, 78 0                                            \n",
      "====================================================================================================\n",
      "Total params: 404,244.0\n",
      "Trainable params: 404,244.0\n",
      "Non-trainable params: 0.0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build a model to project inputs on the latent space\n",
    "encoder = Model(x, z_mean)\n",
    "\n",
    "# display a 2D plot of the digit classes in the latent space\n",
    "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# build a digit generator that can sample from the learned distribution\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "_h_decoded = decoder_h(decoder_input)\n",
    "_x_decoded_mean = decoder_mean(_h_decoded)\n",
    "generator = Model(decoder_input, _x_decoded_mean)\n",
    "\n",
    "# display a 2D manifold of the digits\n",
    "n = 15  # figure with 15x15 digits\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "# linearly spaced coordinates on the unit square were transformed through the inverse CDF (ppf) of the Gaussian\n",
    "# to produce values of the latent variables z, since the prior of the latent space is Gaussian\n",
    "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        x_decoded = generator.predict(z_sample)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure, cmap='Greys_r')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
