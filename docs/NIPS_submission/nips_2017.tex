\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
% \PassOptionsToPackage{numbers, compress}{natbib}
% before loading nips_2017
%!TEX encoding = UTF-8 Unicode
% to avoid loading the natbib package, add option nonatbib:
% \usepackage[nonatbib]{nips_2017}

\usepackage[final, nonatbib]{nips_2017}

%\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{graphicx}
\usepackage{pgfplotstable}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{csvsimple}
\usepackage{subcaption}
\usepackage[normalem]{ulem}

\newcommand*{\figuretitle}[1]{%
    {\centering%   <--------  will only affect the title because of the grouping (by the
    \textbf{#1}%              braces before \centering and behind \medskip). If you remove
    \par\medskip}%            these braces the whole body of a {figure} env will be centered.
}

\graphicspath{{/Users/fonz/Documents/Projects/GTEx/plotting/}}

\title{Explaining gene expression in histopathology using image features derived from neural networks}


% to compile a camera-ready version, add the [final] optio name.
\definecolor{ao(english)}{rgb}{0.0, 0.5, 0.0}
\definecolor{figgreen}{rgb}{0.106, 0.62, 0.467}
\definecolor{figorange}{rgb}{0.851, 0.373, 0.008}
\definecolor{figpurple}{rgb}{0.459, 0.439, 0.702}
\author{
  William Jones\\
  Wellcome Trust Sanger Institute\\
  Hinxton\\
  UK, CB10 1SA \\
  \texttt{wj2@sanger.ac.uk} \\
  %% examples of more authors
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \AND
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
}
%
\begin{document}
% \nipsfinalcopy is no longer used

\maketitle

\begin{abstract}
We investigate to what extent gene expression can be predicted using features extracted from biomedical images. We use data from the Genotype Tissue Expression (GTEx) project comprising high resolution histopathology images with annotated bulk RNA expression and genotype data. We define image features by taking the penultimate layer activations from InceptioNet-v3, after retraining the model to differentiate between 10 tissue types. After aggregating these feature across a tissue segment, we find that in many tissues, and for small patch sizes, we can explain significantly more of the variation in gene expression (>12\% more in Lung tissue) than when using permuted image features. We find that technical factors drive a significant proportion of variation in both the image features (40.6\%) and gene expression (51.1\%). After taking into account technical variation, we find that the variation of certain transcripts can be explained by individual image features (44\% for some transcripts in Lung). This work indicates that expression biomarkers could soon be estimated using biomedical images. \end{abstract}

\section{Introduction}
Biomedical images are routinely used by doctors in pathology to diagnose disease. For example, Lung biopsies are taken from patients when grading severities of Lung cancers \cite{histology-classification-lung-cancer}. Specifically for lung cancer, a great deal of work has focussed on the identification of specific tissue characteristics which are indicative of metastasis. Indeed, this has been the topic of many supervised machine learning competition and approaches. We can now accurately identify metastatic regions from high resolution histopathology lung images, with the state of the art achieved by Convolutional Neural Networks (CNNs) \cite{detecting-cancer-metastases}.

Pathologists are trained to identify visual characteristics in histological slides that are indicative of disease, and it is known that disease onset triggers changes in bulk RNA expression data in tissues where the disease presents. \cite{gene-expression-parkinsons} Furthermore, in many cases the onset of these has a genetic component \cite{what-is-complex-about-complex-disorders}. Therefore, it is reasonable to conclude that high resolution images contain information pertaining to the bulk RNA expression profile taken from the sample, and perhaps even the donor genotype.

Until recently the absence such datasets has prohibited work in this direction. With the addition of high resolution histopathology images annotated with gene expression data, and genotypes, as part of the Genotype Tissue Expression Project (GTEx Project) \cite{GTEx-project}, it is now possible to investigate the interplay of histopathology images, gene expression and genetics. At the time of analysis, the repository (v6), consisted of 449 genotyped individuals, along with bulk RNA expression from 44 tissue types \cite{GTEx-histology}. A median of 15 tissues were donated per individual, and a median of 155 samples of each tissue are available in total. High resolution histopathology images were available for 34 of these tissue types.

\section{Methods}

\subsubsection{Training data generation}

We segment the tissue slice into foreground and background by grayscaling the image, using a Gaussian blur \cite{shapiro-computer-vision} with kernel (51,51) (Figure \ref{fig:extracting_tissue_patches} \textcolor{ao(english)}{A}), followed by Otsu thresholding \cite{otsu-method}. Following this, given a patch size, $s$, we find all patches of size $s$ that lie within the tissue boundary. (Figure \ref{fig:extracting_tissue_patches} \textcolor{ao(english)}{B})


\subsubsection{Neural network model}
We use Inceptionet-v3 \cite{inception}, a 220-layer Convolutional Neural Network with pre-trained weights to distinguish everyday objects in images. We follow the common practice of adjusting the network architecture in order to fine-tune the network and repurpose it for a different task. To finetune this network, we add a GlobalAveragePooling layer \cite{network-in-network} followed by a Dense layer a neural network, and a final softmax layer with 10 classification neurons.

When varying the size of patches, we re-scale all patches to be 299x299 pixels. This means that if we classify a patch of size 4096, the size is reduced to be 299x299. If the patch-size is 128x128, then we use bi-linear interpolation to resize the patch to be 299x299 pixels. 

\begin{wrapfigure}{r}{0.5\textwidth}
	\figuretitle{Extracting tissue patches}
	\begin{center}
	    \includegraphics[width=1\linewidth]{/FeatureExploration/extracting_tissue_patches} 
	\end{center}
	\caption{}
  \label{fig:extracting_tissue_patches}
\end{wrapfigure}


\subsubsection{Training and Evaluation}
We fine-tuned our modified version of InceptioNet to classify square image patches into their originating tissue types. We use the categorical cross-entropy loss function with Stochastic Gradient Descent with learning rate 0.0001 and momentum = 0.9. We run the back-propagation algorithm to fine-tune the network by first updating the final-layer weights for 10 epoch and then updating the InceptionNet-v3 layer weights for 30 epochs. We used Keras 2.0 \cite{keras} to build and train the neural networks. We use OpenSlide Python \cite{openslide}  version 1.1.1 to read in the whole slide images.


We assess the performance of the classifier on the held-out validation set by reporting the percentage of correctly classified tissues.

\subsection{Aggregated features}

We generated image features for each image, using individual lung patches via the following steps: First, we pass every patch that lies within a tissue boundary through the raw and retrained InceptioNet networks, and at each patch-size, to obtain an image feature vector of length $1024$ for each patch. Then, we aggregate the image feature across all image patches using the mean.

In detail, for image $i$, patch $j$, I obtain the $k$th raw patch feature as: $r_{ijk} =  InceptioNet(x_{ij})_k$

and, after aggregation, the final image level features is defined as: $f_{ik} = \frac{1}{J}\sum_j r_{ijk}$ where $J$ is the total number of patches lying within a tissue boundary.


\subsection{Associating aggregated features to RNA expression}

The RNA expression data was download from the GTEx portal and are recorded in log RPKM values. To investigate strong drivers of variation between the the expression data and the image features, we performed Pearson Correlation tests between the principal components describing the 95\% of the variation in the image features and expression respectively. To investigate individual transcript-feature relationships, we generated sample level features in Lung tissue, for a patch-size of 256x256 pixels with the mean as the aggregation method.


%\begin{wrapfigure}{l}{0.4\textwidth}
%\figuretitle{Expression Cutoffs}
%	\begin{center}
%	  \includegraphics[width=1\linewidth]{/FeatureExploration/expression_means_and_stds}
%	\end{center}
%	\caption{}
%	\label{fig:expression_means_and_stds}
%%  \caption{Summary statistics of expression levels used for gene filtering \textcolor{ao(english)}{A} Frequency (y-axis) of mean transcript expression across samples (x-axis). Red vertical line corresponds to x=1, and was used as a minimum expression level cutoff for inclusion in the analysed dataset. \textcolor{ao(english)}{B} Frequency (y-axis) of the standard deviation of transcript expression across samples (x-axis) that have mean expression greater than 1. Samples to the right of the vertical red line correspond to the 2000 most varying transcripts.}
%\end{wrapfigure}

\subsection{Calculating residual features and estimate variance composition}
We regress out technical effects from both expression and image features by fitting a linear model using all 51 technical factors as predictors and subtracting the predicted values.

We selected the top 2000 varying transcripts which had mean expression greater than $1$ for each tissue type. We display where the expression cutoff falls on the histograms of expression mean standard deviations respectivel. We investigate the Pearson Correlation tests for each of these pairs or transcript and features. These correlations are reported together with a p-value representing the probability that the R score was found by chance.

We cross correlate the expression and image principle components that explain 99.9\% of variation in each respective dataset, and derive the total fraction of expression variance explained by the image features. We calculate $\sum_i \lambda_i \sum_j r^2_{ij} $ where $\lambda_i$ is the $i$th eigenvalue of the image feature PCA and $r^2_{ij}$ is the correlation of image feature PC $i$ with expression feature PC $j$. We recalculate the proportion of variance explained after regressing out known technical factors to derive the proportion of variation explained by the image features, outside of known technical variation.


\section{Results}

\begin{figure}[h]
\centering
\figuretitle{Individual Feature Transcript Associations in Lung}
    \includegraphics[width=1\textwidth]{/TFCorrectedFeatureAssociations/top_corrected_associations}
 \caption{}
 \label{fig:top_corrected_associations}
\end{figure}

We find that across 10 different tissue types, a large amount of variation in expression can be explained with a combination of known technical factors and image features. (Figure \ref{fig:variance_composition}). We find that across a number of tissues, more variance is explained using image features from the retrained InceptioNet model than permuted image features.

\begin{wrapfigure}{r}{0.5\textwidth}
        \figuretitle{\% Variance explained by Technical Factors}
	\begin{center}
	\includegraphics[width=1\linewidth]{/TFCorrectedFeatureAssociations/tf_feature_selection} 
	\end{center}
	\caption{}
  \label{fig:tf_feature_selection}
\end{wrapfigure}


RNA degradation number (SMRIN) was the factor that explained the most (11.8\%) variation in the image features, wheres Ischemic time explained the most the variance (12.7\%) in the expression data (Figure \ref{fig:tf_feature_selection}). In total for Lung tissue, technical factors explained 51.1\% of the variation in expression and 40.6\% of the variation in the image features generated at a patch size of $256$.

After regressing out the effect of technical covariates from both the image features and expression, we find that for some transcripts (e.g. AGER) as much as 44\% of the variation can be explained by individual image features (Figure \ref{fig:top_corrected_associations}).




For Lung tissue, we find that feature 501 explains a significant amount of variation for gene transcripts that are enriched for the gene ontology term: Defective ABCA3 causes pulmonary surfactant metabolism dysfunction type 3 (SMDP3) (Table \ref{tab:image_feature_pcs_and_tfs}). This condition is known to be visually identifiable by pathologists via histopathology \cite{surfectant-dysfunction}.  Also in Lung tissue, a specific image feature that was highly predictive of Ischemic time (the duration of time between donor death and tissue harvesting) appeared to capture the global colour (Figure \ref{fig:image_feature_796_vs_SMTSISCH}) across the entire tissue area (Figure \ref{fig:top5_bottom5_feature796}).

\begin{figure}[h]
\figuretitle{Feature Interpretation}
\begin{subfigure}{0.6\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{/FeatureExploration/top5_bottom5_feature796}
    \caption{Image feature 796 appears to capture global tissue colour. Top row displays top five Lung samples that activate the feature, bottom row displays bottom five.}
    \label{fig:top5_bottom5_feature796}
\end{subfigure}
\begin{subfigure}{0.3\textwidth}
    \centering
    \includegraphics[width=0.75\textwidth]{/RawFeatureAssociations/image_feature_796_vs_SMTSISCH}
    \caption{Image feature 796 strongly predicts Ischemic time (SMTSISCH).}
    \label{fig:image_feature_796_vs_SMTSISCH}
 \end{subfigure}
 \caption{}
\end{figure}

\section{Discussion}

We demonstrate that estimates about gene expression can be estimate using histopathology images features alone. This study motivates further work that aims to close the information boundary between biomedical images and gene expression markers. Future work will aim to predict the variation of specific expression markers for a given disease for diagnosis. This work will require more comprehensive datasets, but with modern day neural networks able to successfully perform function approximation for a wide variety of complex tasks, this might soon be possible.

%\begin{figure}[h]
%\figuretitle{Filtering expression matrix}
%\includegraphics[width=1\linewidth]{/FeatureExploration/expression_means_and_stds}
%\caption{Summary statistics of expression levels used for gene filtering \textcolor{ao(english)}{A} Frequency (y-axis) of mean transcript expression across samples (x-axis). Red vertical line corresponds to x=1, and was used as a minimum expression level cutoff for inclusion in the analysed dataset. \textcolor{ao(english)}{B} Frequency (y-axis) of the standard deviation of transcript expression across samples (x-axis) that have mean expression greater than 1. Samples to the right of the vertical red line correspond to the 2000 most varying transcripts.}
%\label{fig:expression_means_and_stds}
%\end{figure}







\begin{figure}[h]
  \figuretitle{Variance Components}
  \centering
    \includegraphics[width=0.8\linewidth]{/VarianceComposition/compare_expression_variance_composition_across_tissues_by_model} 
  \caption{Proportion of the variation in expression \textcolor{figgreen}{explained by image features}, \textcolor{figpurple}{explained by technical factors}, \textcolor{figorange}{unexplained}, for 10 different tissue types using image features from 6 different patch-sizes (in pixels). For each patch-size, the \textbf{left stacked bar} uses retrained InceptioNet features, and \textbf{right stacked bar} uses permuted Inception features.}
  \label{fig:variance_composition}
\end{figure}

%
%\begin{figure}[H]
%    \centering
%      \includegraphics[width=0.5\linewidth]{/TFCorrectedFeatureAssociations/tf_feature_selection} 
%        \caption{Only displaying the top 8 technical factors. In total, technical factors account for 40.6\% of variation in the image features and 51.1\% of variation in expression.}
%        \label{fig:tf_feature_selection}
%\end{figure}
%

\begin{table}[H]
\figuretitle{Enriched Ontology Terms for feature 501}
\caption{}
\label{tab:image_feature_pcs_and_tfs}       % Give a unique label

\begin{tabular}{p{2cm}p{6cm}p{6cm}}
\hline\noalign{\smallskip}
p-value & Ontology & Genes  \\
1.21e-15 & lamellar body & LAMP3,CTSH,SFTPA1,NAPSA,SFTPD  \\
6.87e-09 & Defective ABCA3 causes pulmonary surfactant metabolism dysfunction type 3 (SMDP3) & SFTPA1,SFTPD,SFTPB,SFTPA2 \\


%\noalign{\smallskip}\svhline\noalign{\smallskip}
\noalign{\smallskip}\hline\noalign{\smallskip}
\end{tabular}
% $^a$ Table foot note (with superscript)
\end{table}


%
%

%\section*{Plan}
%
%\subsection*{Q1: How much variability is shared between image features and expression?} 
%\begin{enumerate}
%\item \sout{Calculate PCA of image features and expression}
%
%\item \sout{Calculate cross correlations between the PCs until 99.9\% variance is explained.}
%
%\item \sout{Use the cross correlation measurements to derive total fraction of variance explained of images by expression: calculate $\sum_i \lambda_i \sum_j r^2_{ij} $ where $\lambda_i$ is the $i$th eigenvalue of the image feature PCA, $r^2_{ij}$ is the correlation of image feature PC $i$ with expression feature PC $j$.}
%
%\item \sout{Make all of the above one-line-to-run for any combination of patch size, feature layer, tissue}
%
%\item \sout{Report the value for each patch size, feature layer, tissue;} interpret findings
%
%\end{enumerate}
%
%\subsection*{Q2: How much of the shared variability is due to technical confounders?} 
%
%\begin{enumerate}
%\item \sout{Regress out known confounders $C$ from the image feature $F$ and expression data E. I.e., fit models $F \sim C + \epsilon$ and $E \sim C + \epsilon$. Use log scale for Ischemic time, monitor all scatter plots for confounders that are included in the model that the linear model assumptions hold. Decide whether to retain full model of all confounders x all genes/features, retain only significant associations, or do forward feature selection.}
%
%\item \sout{Repeat steps Q1:1-5 above using the residuals of this model. }
%
%\item \sout{Create a scatter plot of total shared variance vs. technical shared variance [again, all tissues etc.]}
%
%\item Interpret findings in context of many tissues, scales, feature layers
%\end{enumerate}
%
%\subsection*{Q3: What genes share expression variability to visual features, and at which scales?}
%\begin{enumerate}
%\item \sout{Using residuals of technical confounders, fit linear model of expression vs. image feature - calculate effect sizes and p-values}
%
%\item \sout{Apply multiple testing correction to derive a list of image feature associated genes.}
%
%\item \sout{Sort genes based on variance explained by each image feature, perform GSEA or gProfiler ranked gene list analysis to test whether particular aspects of biology are enriched.} Interpret
%
%\item Assess number of associations [total and per-feature] for different tissues, feature scales. Assess overlap of findings from gene list analyses. Interpret.
%\end{enumerate}
%
%\subsection*{Q3A: What genes are influenced by technical confounders?}
%\begin{enumerate}
%
%\item For each confounder, calculate the fraction of variance it explains for each gene expression level. 
%
%\item Sort genes based on variance explained by confounder, perform GSEA or gProfiler ranked gene list analysis to test whether particular aspects of biology are enriched.]
%
%\end{enumerate}
%
%\subsection*{Once these done}
%\begin{itemize}
%\item Q4: What do the image features represent?
%\item Q5: Is there a genetic basis to the image features?
%\item Q6: Are there gene expression levels that cause image feature changes, or vice versa?
%\item Q7: Are there image features that are associated with clinical annotations? Are any causal?
%
%\end{itemize}
%
%
%\section*{Results}


%\begin{figure}[H]
%  \centering
%    \includegraphics[width=1\linewidth]{/TFCorrectedFeatureAssociations/tf_feature_selection_image_features} 
%  \caption{Sample figure caption.}
%\end{figure}

%\pgfplotstableset{col sep=comma}{plotting/NIPS/ontology_results.csv}

\input{referenc}
\end{document}
